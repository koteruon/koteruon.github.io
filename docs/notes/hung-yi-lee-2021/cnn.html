<!doctype html>
<html lang="zh-Hant" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-notes/hung-yi-lee-2021/cnn" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">卷積神經網路 (Convolutional Neural Network, CNN) | Chao-En Huang</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://koteruon.github.io/images/icon/chao_en_huang_icon.png"><meta data-rh="true" name="twitter:image" content="https://koteruon.github.io/images/icon/chao_en_huang_icon.png"><meta data-rh="true" property="og:url" content="https://koteruon.github.io/docs/notes/hung-yi-lee-2021/cnn"><meta data-rh="true" property="og:locale" content="zh_Hant"><meta data-rh="true" name="docusaurus_locale" content="zh-Hant"><meta data-rh="true" name="docsearch:language" content="zh-Hant"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="卷積神經網路 (Convolutional Neural Network, CNN) | Chao-En Huang"><meta data-rh="true" name="description" content="影像輸入設計：Flatten 方法的問題與反思"><meta data-rh="true" property="og:description" content="影像輸入設計：Flatten 方法的問題與反思"><link data-rh="true" rel="icon" href="/images/icon/favicon.ico"><link data-rh="true" rel="canonical" href="https://koteruon.github.io/docs/notes/hung-yi-lee-2021/cnn"><link data-rh="true" rel="alternate" href="https://koteruon.github.io/docs/notes/hung-yi-lee-2021/cnn" hreflang="zh-Hant"><link data-rh="true" rel="alternate" href="https://koteruon.github.io/docs/notes/hung-yi-lee-2021/cnn" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Chao-En Huang RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Chao-En Huang Atom Feed">

<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-5X8N2TCV",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer")</script>





<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.42b2a4f7.css">
<script src="/assets/js/runtime~main.1b55d083.js" defer="defer"></script>
<script src="/assets/js/main.24e9599a.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5X8N2TCV" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>


<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="跳至主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳至主要内容</a></div><nav aria-label="主導航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切換導覽列" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/images/icon/apple-touch-icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/images/icon/apple-touch-icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Chao-En</b></a><a class="navbar__item navbar__link" href="/about-me">About Me</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/notes">Notes</a><a class="navbar__item navbar__link" href="/docs/research">Research</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/koteruon" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="切換淺色/深色模式（當前為淺色模式）" aria-label="切換淺色/深色模式（當前為淺色模式）" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="回到頂部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="文件側邊欄" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/notes">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/docs/notes/hung-yi-lee-2021/machine-learning-basics">李宏毅機器學習 2021</a><button aria-label="收起側邊欄分類 &#x27;李宏毅機器學習 2021&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2021/machine-learning-basics">機器學習基本概念簡介</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2021/machine-learning-task-guide">機器學習任務攻略</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2021/deep-learning-optimization-critical-point">深度學習中的優化技巧 - 臨界點 (Critical Point)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2021/deep-learning-optimization-batch-momentum">深度學習中的優化技巧 - 批次 (Batch) 與動量 (Momentum)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2021/deep-learning-optimization-adaptive-learning-rate">深度學習中的優化技巧 - 自動調整學習速率 (Adaptive Learning Rate)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2021/deep-learning-optimization-classification">深度學習中的優化技巧 - 分類 (Classification)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2021/deep-learning-optimization-batch-normalization">深度學習中的優化技巧 - 批次標準化 (Batch Normalization, BN)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/notes/hung-yi-lee-2021/cnn">卷積神經網路 (Convolutional Neural Network, CNN)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2021/self-attention">自注意力機制 (Self-attention)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2021/transformer">Transformer</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/notes/hung-yi-lee-2024/what-is-generative-ai">李宏毅生成式AI 2024</a><button aria-label="展開側邊欄分類 &#x27;李宏毅生成式AI 2024&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/notes/design-pattern">Design Patterns</a><button aria-label="展開側邊欄分類 &#x27;Design Patterns&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/notes/docker-basics">Docker Basics</a><button aria-label="展開側邊欄分類 &#x27;Docker Basics&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/notes/kubernetes-basics">Kubernetes Basics</a><button aria-label="展開側邊欄分類 &#x27;Kubernetes Basics&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/notes/owasp-top10-2021">OWASP Top 10 (2021)</a><button aria-label="展開側邊欄分類 &#x27;OWASP Top 10 (2021)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/notes/ollama">Ollama</a><button aria-label="展開側邊欄分類 &#x27;Ollama&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="頁面路徑"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="主頁面" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/notes/hung-yi-lee-2021/machine-learning-basics"><span itemprop="name">李宏毅機器學習 2021</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">卷積神經網路 (Convolutional Neural Network, CNN)</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本頁導覽</button></div><div class="theme-doc-markdown markdown"><header><h1>卷積神經網路 (Convolutional Neural Network, CNN)</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="影像輸入設計flatten-方法的問題與反思">影像輸入設計：Flatten 方法的問題與反思<a href="#影像輸入設計flatten-方法的問題與反思" class="hash-link" aria-label="影像輸入設計：Flatten 方法的問題與反思的直接連結" title="影像輸入設計：Flatten 方法的問題與反思的直接連結">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="基本步驟">基本步驟<a href="#基本步驟" class="hash-link" aria-label="基本步驟的直接連結" title="基本步驟的直接連結">​</a></h3>
<ol>
<li><strong>影像縮放 (Rescale)</strong>：將圖片統一成固定大小（如 100 × 100）,。</li>
<li><strong>獨熱向量 (One-hot Vector)</strong>：表示類別，維度長度決定可辨識的種類數量。</li>
<li><strong>模型優化</strong>：通過 Softmax 後，追求預測值與正確標籤間的 Cross Entropy 最小化。</li>
</ol>
<p><img decoding="async" loading="lazy" alt="fully-connected-network-1" src="/assets/images/fully-connected-network-1-481f3560225f3297c2f59e87fb43b512.png" width="960" height="720" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="將圖片輸入到模型中">將圖片輸入到模型中<a href="#將圖片輸入到模型中" class="hash-link" aria-label="將圖片輸入到模型中的直接連結" title="將圖片輸入到模型中的直接連結">​</a></h3>
<ul>
<li><strong>影像表示</strong>：彩色影像為三維張量 (Tensor)，包含寬、高及 R G B 三個通道 (Channel)。</li>
<li><strong>直覺思路</strong>：直接展平 (Flatten) 為向量輸入。</li>
<li><strong>問題</strong>：<strong>參數量過大</strong>。如 100×100×3 輸入配 1000 個神經元，第一層即需 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><msup><mn>10</mn><mn>7</mn></msup></mrow><annotation encoding="application/x-tex">3 \times 10^7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">7</span></span></span></span></span></span></span></span></span></span></span> 個權重，大幅增加 <strong>Overfitting 風險</strong>。</li>
</ul>
<p><img decoding="async" loading="lazy" alt="fully-connected-network-2" src="/assets/images/fully-connected-network-2-1cdd139961a61d4a503d87341d471178.png" width="960" height="720" class="img_ev3q"></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="為什麼需要-cnn-設計動機與影像特性">為什麼需要 CNN？ (設計動機與影像特性)<a href="#為什麼需要-cnn-設計動機與影像特性" class="hash-link" aria-label="為 什麼需要 CNN？ (設計動機與影像特性)的直接連結" title="為什麼需要 CNN？ (設計動機與影像特性)的直接連結">​</a></h2>
<p>在處理影像辨識時，若直接使用全連接網路 (Fully Connected Network)，會面臨<strong>參數過多</strong>導致 <strong>Overfitting</strong> 的風險。CNN 透過對影像特性的三個關鍵觀察來簡化網路架構：</p>
<ol>
<li>
<p><strong>觀察一：偵測 Pattern 不需要看整張圖片</strong></p>
<ul>
<li>影像中的重要特徵（如鳥嘴、眼睛）通常只存在於局部區域。
<img decoding="async" loading="lazy" alt="observation-1" src="/assets/images/observation-1-8d2721915936743777975ccafc802cdd.png" width="960" height="720" class="img_ev3q"></li>
<li><strong>簡化方式：</strong> 引入 <strong>Receptive Field (感受野)</strong>，每個神經元只負責守備一小塊區域。<!-- -->
<table><thead><tr><th style="text-align:center"><img decoding="async" loading="lazy" alt="receptive-field-1" src="/assets/images/receptive-field-1-a50d088929b146cdb993c4e07a850cfe.png" width="960" height="720" class="img_ev3q"></th><th style="text-align:center"><img decoding="async" loading="lazy" alt="receptive-field-2" src="/assets/images/receptive-field-2-fa27c0ffe33413442fd4460028fecc25.png" width="960" height="720" class="img_ev3q"></th></tr></thead><tbody><tr><td style="text-align:center"><strong>單一神經元的局部感受野計算</strong></td><td style="text-align:center"><strong>共享感受野的卷積特徵擷取</strong></td></tr></tbody></table>
</li>
</ul>
</li>
<li>
<p><strong>觀察二：同樣的 Pattern 會出現在不同位置</strong></p>
<ul>
<li>鳥嘴可能出現在左上角，也可能出現在中間。
<img decoding="async" loading="lazy" alt="observation-2" src="/assets/images/observation-2-88785a8989203a40d30707c2c7ee4b23.png" width="960" height="720" class="img_ev3q"></li>
<li><strong>簡化方式：</strong> <strong>Parameter Sharing (參數共享)</strong>。讓不同守備範圍的神 經元共用同一組參數（即 Filter）。<!-- -->
<table><thead><tr><th style="text-align:center"><img decoding="async" loading="lazy" alt="parameter-sharing-1" src="/assets/images/parameter-sharing-1-abdf8c675800aa390a4efe8276a60e8d.png" width="960" height="720" class="img_ev3q"></th><th style="text-align:center"><img decoding="async" loading="lazy" alt="parameter-sharing-2" src="/assets/images/parameter-sharing-2-99b8f94df1d1c75b705b725b8711430b.png" width="960" height="720" class="img_ev3q"></th></tr></thead><tbody><tr><td style="text-align:center"><strong>共享參數、不同感受野，產生不同輸出</strong></td><td style="text-align:center"><strong>不同感受野皆套用相同的 Filter（權重共享）</strong></td></tr></tbody></table>
</li>
</ul>
</li>
<li>
<p><strong>觀察三：對影像做下採樣 (Subsampling) 不影響辨識</strong></p>
<ul>
<li>將圖片縮小後，人依然能辨認出物件。
<img decoding="async" loading="lazy" alt="observation-3" src="/assets/images/observation-3-4387cad72ca9f9ee5cf6c298a22ebc72.png" width="960" height="720" class="img_ev3q"></li>
<li><strong>簡化方式：</strong> <strong>Pooling (池化)</strong>。縮小圖片尺寸以減少運算量。</li>
</ul>
</li>
</ol>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="卷積層的優勢受限的-fully-connected-layer">卷積層的優勢：受限的 Fully Connected Layer<a href="#卷積層的優勢受限的-fully-connected-layer" class="hash-link" aria-label="卷積層的優勢：受限的 Fully Connected Layer的直接連結" title="卷積層的優勢：受限的 Fully Connected Layer的直接連結">​</a></h2>
<p>卷積層 (Convolutional Layer) 本質上是 <strong>加上人為限制（Model Bias）</strong> 的 Fully Connected (FC) Layer，透過犧牲模型彈性來換取更好的訓練效率與抗過擬合能力。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="核心觀察從-fc-到-cnn-的限制"><strong>核心觀察：從 FC 到 CNN 的限制</strong><a href="#核心觀察從-fc-到-cnn-的限制" class="hash-link" aria-label="核心觀察從-fc-到-cnn-的限制的直接連結" title="核心觀察從-fc-到-cnn-的限制的直接連結">​</a></h3>
<ol>
<li><strong>感受野 (Receptive Field)</strong>：FC 原本能決定看整張圖片或局部範圍（將多餘權重設為 0），但 CNN 強制限制神經元<strong>只能守備特定範圍</strong>。</li>
<li><strong>權值共享 (Parameter Sharing)</strong>：FC 的神經元參數各自獨立，但 CNN 強制守備不同區域的同一組 Filter <strong>必須共用參數</strong>。</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="效能分析靈活性與偏置的平衡"><strong>效能分析：靈活性與偏置的平衡</strong><a href="#效能分析靈活性與偏置的平衡" class="hash-link" aria-label="效能分析靈活性與偏置的平衡的直接連結" title="效能分析靈活性與偏置的平衡的直接連結">​</a></h3>
<ul>
<li><strong>全連接層 (FC)</strong>：<strong>Model Bias 小、靈活性 (Flexibility) 極高</strong>。雖然能產生各類變化，但在特定任務（如影像辨識）上容易因參數量過大而導致 <strong>Overfitting</strong>，難以在特定任務上做好。</li>
<li><strong>卷積層 (CNN)</strong>：<strong>Model Bias 較大</strong>。雖然限制了模型的自由度，但它是<strong>專門為影像特性設計</strong>的（考慮局部性與平移不變性），因此在影像處理任務上表現更穩健且優異。</li>
</ul>
<p><img decoding="async" loading="lazy" alt="benefit-of-convolutional-layer" src="/assets/images/benefit-of-convolutional-layer-9588b21d6f7e2fab4d38a3646f4293cf.png" width="960" height="720" class="img_ev3q"></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="濾波器角度-filter-perspective-介紹-cnn">濾波器角度 (Filter Perspective) 介紹 CNN<a href="#濾波器角度-filter-perspective-介紹-cnn" class="hash-link" aria-label="濾波器角度 (Filter Perspective) 介紹 CNN的直接連結" title="  濾波器角度 (Filter Perspective) 介紹 CNN的直接連結">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="卷積層基本定義">卷積層基本定義<a href="#卷積層基本定義" class="hash-link" aria-label="卷積層基本定義的直接連結" title="卷積層基本定義的直接連結">​</a></h3>
<ul>
<li><strong>濾波器 (Filter) 的作用</strong>：卷積層包含多個 Filter，每個 Filter 都是一個三維張量（如 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn><mo>×</mo><mtext>Channel</mtext></mrow><annotation encoding="application/x-tex">3 \times 3 \times \text{Channel}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord text"><span class="mord">Channel</span></span></span></span></span>），其任務是偵測影像中特定的 <strong>Pattern</strong>。</li>
<li><strong>參數本質</strong>：Filter 內的數值即為模型待學習的 <strong>權值 (Weight)</strong>，有時也包含偏置 (Bias)。</li>
<li><strong>運算方式：內積 (Inner Product)</strong>：Filter 與圖片對應區域的數值進行矩陣相乘後求和。當圖片出現與 Filter 相似的特徵時，內積數值最大。</li>
<li><strong>特徵圖 (Feature Map)</strong>：每個 Filter 掃過整張圖片後會產生一組數值。若有 64 個 Filter，就會產生 64 個 Channel 的新圖片，稱為 <strong>Feature Map</strong>。</li>
</ul>
<table><thead><tr><th style="text-align:center"><img decoding="async" loading="lazy" alt="filter" src="/assets/images/filter-31738bdde3c52fa15316f14a116b345d.png" width="960" height="720" class="img_ev3q"></th><th style="text-align:center"><img decoding="async" loading="lazy" alt="feature-map" src="/assets/images/feature-map-2d32c8949b22c7fed892b2322afb3723.png" width="960" height="720" class="img_ev3q"></th></tr></thead><tbody><tr><td style="text-align:center"><strong>Filter 透過內積運算偵測影像特定 Pattern</strong></td><td style="text-align:center"><strong>多個 Filter 各自產生特徵圖，構成多通道 Feature Map</strong></td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="多層卷積機制">多層卷積機制<a href="#多層卷積機制" class="hash-link" aria-label="多層卷積機制的直接連結" title="多層卷積機制的直接連結">​</a></h3>
<ul>
<li><strong>深度匹配</strong>：第二層卷積的 Filter <strong>高度（深度）必須等於第一層輸出的 Channel 數</strong>（例如前層輸出 64 個 Channel，後層 Filter 的深度即為 64）。</li>
<li><strong>視野演進 (Receptive Field Evolution)</strong>：即使 Filter 大小固定（如 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3 \times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3</span></span></span></span>），隨著網路  疊深，深層神經元在原圖上考慮的範圍會越來越大（如第二層的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3 \times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3</span></span></span></span> 實際上對應原圖的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5 \times 5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">5</span></span></span></span>），因此<strong>深層網路能偵測更大尺寸的 Pattern</strong>。</li>
</ul>
<table><thead><tr><th style="text-align:center"><img decoding="async" loading="lazy" alt="multiple-convolutional-layer-1" src="/assets/images/multiple-convolutional-layer-1-a3d5bc689578818be81ce3bb2305d91a.png" width="960" height="720" class="img_ev3q"></th><th style="text-align:center"><img decoding="async" loading="lazy" alt="multiple-convolutional-layer-2" src="/assets/images/multiple-convolutional-layer-2-e0d12f60bb57b42d2ce24c3949f68e0e.png" width="960" height="720" class="img_ev3q"></th></tr></thead><tbody><tr><td style="text-align:center"><strong>後層 Filter 深度需對齊前層 Channel 數</strong></td><td style="text-align:center"><strong>卷積層加深使感受野逐步擴大</strong></td></tr></tbody></table>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="神經元角度-neuron-vs-濾波器角度-filter">神經元角度 (Neuron) vs. 濾波器角度 (Filter)<a href="#神經元角度-neuron-vs-濾波器角度-filter" class="hash-link" aria-label="神經元角度 (Neuron) vs. 濾波器角度 (Filter)的直接連結" title="神經元角度 (Neuron) vs. 濾波器角度 (Filter)的直接連結">​</a></h2>
<p>這兩種觀點在數學上是一模一樣的，只是從不同視角來說明 CNN 的機制。</p>
<table><thead><tr><th style="text-align:center">影像特性與觀察</th><th style="text-align:center"><strong>神經元角度 (Neuron)</strong></th><th style="text-align:center"><strong>濾波器角度 (Filter)</strong></th></tr></thead><tbody><tr><td style="text-align:center"><strong>觀察一：局部性</strong> (不需看整張圖)</td><td style="text-align:center">神經元只守備特定的 <strong>感受野 (Receptive Field)</strong></td><td style="text-align:center">使用 <strong>Filter</strong> 偵測局部範圍內的 Pattern</td></tr><tr><td style="text-align:center"><strong>觀察二：平移不變性</strong> (Pattern 會出現在不同位置)</td><td style="text-align:center">守備不同區域的神經元可以 <strong>共用參數 (Shared Weights)</strong></td><td style="text-align:center">同一個 <strong>Filter 掃過 (Slide)</strong> 整張圖片進行運算（即卷積操作）</td></tr></tbody></table>
<p><strong>核心結論</strong>：
所謂的 <strong>「參數共享」</strong>，本質上就是將一組 <strong>「Filter」</strong> 掃過整張影像。這種設計賦予了 CNN 強大的 <strong>Model Bias</strong>，使其在影像任務上比全連接層更有效率且不易過擬合。</p>
<p><img decoding="async" loading="lazy" alt="neuron-vs-filter" src="/assets/images/neuron-vs-filter-ad30237edec55857d4dc35c23fe3017b.png" width="960" height="720" class="img_ev3q"></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="cnn-的核心結構">CNN 的核心結構<a href="#cnn-的核心結構" class="hash-link" aria-label="CNN 的核心結構的直接連結" title="CNN 的核心結構的直接連結">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="卷積層-convolutional-layer">卷積層 (Convolutional Layer)<a href="#卷積層-convolutional-layer" class="hash-link" aria-label="卷積層 (Convolutional Layer)的直接連結" title="卷積層 (Convolutional Layer)的直接連結">​</a></h3>
<p>卷積層是 <strong>Receptive Field</strong> 與 <strong>Parameter Sharing</strong> 的結合，其 Model Bias 較大（針對影像設計），但能有效避免 Overfitting。</p>
<ul>
<li><strong>濾波器 (Filter)：</strong> 每個 Filter 是一個三維 Tensor（長 × 寬 × 通道數），負責偵測特定的 Pattern。</li>
<li><strong>步長 (Stride)：</strong> Filter 每次移動的距離。</li>
<li><strong>填充 (Padding)：</strong> 若 Filter 超出影像邊界，則補零 (Zero Padding) 或補平均值以維持尺寸。</li>
<li><strong>特徵圖 (Feature Map)：</strong> Filter 掃過整張圖片後的輸出結果。若有 64 個 Filter，就會產生 64 個通道的新圖片。</li>
</ul>
<p><img decoding="async" loading="lazy" alt="typical-setting" src="/assets/images/typical-setting-426bfc4be0ffba129dc41113d85e202a.png" width="960" height="720" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="池化層-pooling">池化層 (Pooling)<a href="#池化層-pooling" class="hash-link" aria-label="池化層 (Pooling)的直接連結" title="池化層 (Pooling)的直接連結">​</a></h3>
<ul>
<li><strong>功能：</strong> 負責把圖片變小，減少運算量。</li>
<li><strong>常見方式：</strong> <strong>Max Pooling</strong> (在一組數字中選最大的作為代表) 或 Mean Pooling。</li>
<li><strong>趨勢：</strong> 隨著運算能力增強，現代有些網路會捨棄 Pooling，改用全卷積架構。</li>
</ul>
<p><img decoding="async" loading="lazy" alt="max-pooling" src="/assets/images/max-pooling-dc3bfd1344292e01ff62f436dc68db05.png" width="960" height="720" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="扁平化與全連接層-flatten--fully-connected-layer">扁平化與全連接層 (Flatten &amp; Fully Connected Layer)<a href="#扁平化與全連接層-flatten--fully-connected-layer" class="hash-link" aria-label="扁平化與全連接層 (Flatten &amp; Fully Connected Layer)的直接連結" title="扁平化與全連接層 (Flatten &amp; Fully Connected Layer)的直接連結">​</a></h3>
<ul>
<li>在經歷多次卷積與池化後，將多維向量 <strong>Flatten (拉直)</strong> 變成一維向量。</li>
<li>最後丟入 Fully Connected Layer 並搭配 <strong>Softmax</strong> 進行分類輸出。</li>
</ul>
<table><thead><tr><th style="text-align:center"><img decoding="async" loading="lazy" alt="convolutional-layer-add-pooling" src="/assets/images/convolutional-layer-add-pooling-0843064c8beeedb4ba8d9c94c907c19f.png" width="960" height="720" class="img_ev3q"></th><th style="text-align:center"><img decoding="async" loading="lazy" alt="the-whole-cnn" src="/assets/images/the-whole-cnn-120ca2fb4cd0bd438736e891dd496e63.png" width="960" height="720" class="img_ev3q"></th></tr></thead><tbody><tr><td style="text-align:center"><strong>卷積與池化逐層抽取影像特徵</strong></td><td style="text-align:center"><strong>特徵學習後進行分類的 CNN 流程</strong></td></tr></tbody></table>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="案例研究alphago">案例研究：AlphaGo<a href="#案例研究alphago" class="hash-link" aria-label="案例研究：AlphaGo的直接連結" title="案例研究：AlphaGo的直接連結">​</a></h2>
<p>雖然下圍棋不是影像辨識，但棋盤具備與影像相似的特性：</p>
<ul>
<li><strong>局部性：</strong> 棋盤上的重要 Pattern（如叫吃）看 5×5 範圍即可辨認。</li>
<li><strong>平移不變性：</strong> 同樣的局勢可以出現在棋盤任何位置。</li>
<li><strong>關鍵差異：</strong> AlphaGo 的設計中<strong>沒有使用 Pooling</strong>，因為棋盤上隨意移除行列會導致資訊嚴重受損。</li>
</ul>
<p><img decoding="async" loading="lazy" alt="alphago" src="/assets/images/alphago-35564c2bf2a10756d25faafbc46ecc62.png" width="960" height="720" class="img_ev3q"></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="cnn-的限制與挑戰">CNN 的限制與挑戰<a href="#cnn-的限制與挑戰" class="hash-link" aria-label="CNN 的限制與挑戰的直接連結" title="CNN 的限制與挑戰的直接連結">​</a></h2>
<ul>
<li><strong>缺乏空間變換不變性：</strong> CNN 無法自動處理影像的<strong>放大縮小 (Scaling)</strong> 或 <strong>旋轉 (Rotation)</strong>。</li>
<li><strong>解決方案：</strong>
<ol>
<li><strong>資料增強 (Data Augmentation)：</strong> 訓練時將圖片截取、放大或旋轉。</li>
<li><strong>Spatial Transformer Layer：</strong> 另一種專門處理此問題的網路架構。</li>
</ol>
</li>
</ul></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文件選項卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/notes/hung-yi-lee-2021/deep-learning-optimization-batch-normalization"><div class="pagination-nav__sublabel">上一頁</div><div class="pagination-nav__label">深度學習中的優化技巧 - 批次標準化 (Batch Normalization, BN)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/notes/hung-yi-lee-2021/self-attention"><div class="pagination-nav__sublabel">下一頁</div><div class="pagination-nav__label">自注意力機制 (Self-attention)</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#影像輸入設計flatten-方法的問題與反思" class="table-of-contents__link toc-highlight">影像輸入設計：Flatten 方法的問題與反思</a><ul><li><a href="#基本步驟" class="table-of-contents__link toc-highlight">基本步驟</a></li><li><a href="#將圖片輸入到模型中" class="table-of-contents__link toc-highlight">將圖片輸入到模型中</a></li></ul></li><li><a href="#為什麼需要-cnn-設計動機與影像特性" class="table-of-contents__link toc-highlight">為什麼需要 CNN？ (設計動機與影像特性)</a></li><li><a href="#卷積層的優勢受限的-fully-connected-layer" class="table-of-contents__link toc-highlight">卷積層的優勢：受限的 Fully Connected Layer</a><ul><li><a href="#核心觀察從-fc-到-cnn-的限制" class="table-of-contents__link toc-highlight"><strong>核心觀察：從 FC 到 CNN 的限制</strong></a></li><li><a href="#效能分析靈活性與偏置的平衡" class="table-of-contents__link toc-highlight"><strong>效能分析：靈活性與偏置的平衡</strong></a></li></ul></li><li><a href="#濾波器角度-filter-perspective-介紹-cnn" class="table-of-contents__link toc-highlight">濾波器角度 (Filter Perspective) 介紹 CNN</a><ul><li><a href="#卷積層基本定義" class="table-of-contents__link toc-highlight">卷積層基本定義</a></li><li><a href="#多層卷積機制" class="table-of-contents__link toc-highlight">多層卷積機制</a></li></ul></li><li><a href="#神經元角度-neuron-vs-濾波器角度-filter" class="table-of-contents__link toc-highlight">神經元角度 (Neuron) vs. 濾波器角度 (Filter)</a></li><li><a href="#cnn-的核心結構" class="table-of-contents__link toc-highlight">CNN 的核心結構</a><ul><li><a href="#卷積層-convolutional-layer" class="table-of-contents__link toc-highlight">卷積層 (Convolutional Layer)</a></li><li><a href="#池化層-pooling" class="table-of-contents__link toc-highlight">池化層 (Pooling)</a></li><li><a href="#扁平化與全連接層-flatten--fully-connected-layer" class="table-of-contents__link toc-highlight">扁平化與全連接層 (Flatten &amp; Fully Connected Layer)</a></li></ul></li><li><a href="#案例研究alphago" class="table-of-contents__link toc-highlight">案例研究：AlphaGo</a></li><li><a href="#cnn-的限制與挑戰" class="table-of-contents__link toc-highlight">CNN 的限制與挑戰</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">This Website</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/notes">Notes</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/research">Research</a></li><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/koteruon" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://profile.104.com.tw/profile/9f11e5a7-4d3b-4a21-9241-ba6e3f9003c8/about" target="_blank" rel="noopener noreferrer" class="footer__link-item">104<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.linkedin.com/in/%E7%85%A7%E6%81%A9-%E9%BB%83-93511b25b" target="_blank" rel="noopener noreferrer" class="footer__link-item">Linkedin<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Acknowledgement</div><ul class="footer__items clean-list"><li class="footer__item">
              <p>
              illustrations by <a href="https://storyset.com/web">Storyset</a>
              </p>
              </li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 Chao-En Huang. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>