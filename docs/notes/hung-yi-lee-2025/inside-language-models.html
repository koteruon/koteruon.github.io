<!doctype html>
<html lang="zh-Hant" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-notes/hung-yi-lee-2025/inside-language-models" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">語言模型內部運作機制剖析 | Chao-En Huang</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://koteruon.github.io/images/icon/chao_en_huang_icon.png"><meta data-rh="true" name="twitter:image" content="https://koteruon.github.io/images/icon/chao_en_huang_icon.png"><meta data-rh="true" property="og:url" content="https://koteruon.github.io/docs/notes/hung-yi-lee-2025/inside-language-models"><meta data-rh="true" property="og:locale" content="zh_Hant"><meta data-rh="true" name="docusaurus_locale" content="zh-Hant"><meta data-rh="true" name="docsearch:language" content="zh-Hant"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="語言模型內部運作機制剖析 | Chao-En Huang"><meta data-rh="true" name="description" content="inside-language-models"><meta data-rh="true" property="og:description" content="inside-language-models"><link data-rh="true" rel="icon" href="/images/icon/favicon.ico"><link data-rh="true" rel="canonical" href="https://koteruon.github.io/docs/notes/hung-yi-lee-2025/inside-language-models"><link data-rh="true" rel="alternate" href="https://koteruon.github.io/docs/notes/hung-yi-lee-2025/inside-language-models" hreflang="zh-Hant"><link data-rh="true" rel="alternate" href="https://koteruon.github.io/docs/notes/hung-yi-lee-2025/inside-language-models" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Chao-En Huang RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Chao-En Huang Atom Feed">

<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-5X8N2TCV",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer")</script>





<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.42b2a4f7.css">
<script src="/assets/js/runtime~main.cc07911e.js" defer="defer"></script>
<script src="/assets/js/main.248e8ac7.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5X8N2TCV" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>


<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="跳至主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳至主要内容</a></div><nav aria-label="主導航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切換導覽列" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/images/icon/apple-touch-icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/images/icon/apple-touch-icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Chao-En</b></a><a class="navbar__item navbar__link" href="/about-me">About Me</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/notes">Notes</a><a class="navbar__item navbar__link" href="/docs/research">Research</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/koteruon" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="切換淺色/深色模式（當前為淺色模式）" aria-label="切換淺色/深色模式（當前為淺色模式）" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="回到頂部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="文件側邊欄" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/notes">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/notes/hung-yi-lee-2021/machine-learning-basics">李宏毅機器學習 2021</a><button aria-label="展開側邊欄分類 &#x27;李宏毅機器學習 2021&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/notes/hung-yi-lee-2024/what-is-generative-ai">李宏毅生成式AI 2024</a><button aria-label="展開側邊欄分類 &#x27;李宏毅生成式AI 2024&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/docs/notes/hung-yi-lee-2025/future-of-generative-ai">李宏毅生成式AI 2025</a><button aria-label="收起側邊欄分類 &#x27;李宏毅生成式AI 2025&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2025/future-of-generative-ai">生成式 AI 的技術突破與未來發展</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2025/principles-of-ai-agents">AI Agent 的定義與運作機制</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/notes/hung-yi-lee-2025/inside-language-models">語言模型內部運作機制剖析</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2025/is-the-transformer-era-ending">Transformer 的時代要結束了嗎？介紹 Transformer 的競爭者們</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2025/power-and-limits-of-pretrain-alignment">大型語言模型訓練方法「預訓練–對齊」的強大與極限</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2025/post-training-and-forgetting">生成式人工智慧的後訓練 (Post-Training) 與遺忘問題</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2025/how-llms-perform-reasoning">DeepSeek-R1 這類大型語言模型是如何進行「深度思考」(Reasoning) 的？</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2025/reasoning-length-is-not-everything">大型語言模型的推理過程不用太長、夠用就好</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2025/challenges-and-myths-of-llm-evaluation">大型語言模型評估 (Evaluation) 的挑戰與迷思</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2025/intro-to-model-editing">人工智慧的微創手術 — 淺談 Model Editing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/notes/hung-yi-lee-2025/an-introduction-to-model-merging">淺談神奇的 Model Merging 技術</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/notes/design-pattern">Design Patterns</a><button aria-label="展開側邊欄分類 &#x27;Design Patterns&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/notes/docker-basics">Docker Basics</a><button aria-label="展開側邊欄分類 &#x27;Docker Basics&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/notes/kubernetes-basics">Kubernetes Basics</a><button aria-label="展開側邊欄分類 &#x27;Kubernetes Basics&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/notes/owasp-top10-2021">OWASP Top 10 (2021)</a><button aria-label="展開側邊欄分類 &#x27;OWASP Top 10 (2021)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/notes/ollama">Ollama</a><button aria-label="展開側邊欄分類 &#x27;Ollama&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="頁面路徑"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="主頁面" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/notes/hung-yi-lee-2025/future-of-generative-ai"><span itemprop="name">李宏毅生成式AI 2025</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">語言模型內部運作機制剖析</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本頁導覽</button></div><div class="theme-doc-markdown markdown"><header><h1>語言模型內部運作機制剖析</h1></header>
<p><img decoding="async" loading="lazy" alt="inside-language-models" src="/assets/images/inside-language-models-1bd1c58d59112aee47a56d980dc2b30d.png" width="1920" height="1080" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="單一個神經元的功能與侷限">單一個神經元的功能與侷限<a href="#單一個神經元的功能與侷限" class="hash-link" aria-label="單一個神經元的功能與侷限的直接連結" title="單一個神經元的功能與侷限的直接連結">​</a></h2>
<ul>
<li><strong>運作定義</strong>：在 Transformer 中，神經元的作用是將輸入向量（紅色  ）進行 <strong>加權總和（Weighted Sum）</strong> 並通過 <strong>啟動函數（如 ReLU）</strong> 後產生輸出（藍色）。
<img decoding="async" loading="lazy" alt="operational-definition" src="/assets/images/operational-definition-fddf70720b8f7a4c59f917de1ea786b5.png" width="1920" height="1080" class="img_ev3q"></li>
<li><strong>檢驗方法</strong>：<!-- -->
<ul>
<li><strong>相關性 (Correlation)</strong>：觀察神經元啟動（輸出 &gt; 0）時是否伴隨特定現象（如模型說髒話），但啟動不代表因果。</li>
<li><strong>因果性 (Causation)</strong>：透過「移除」神經元（將輸出設為 0 或平均值）來觀察現象是否消失，以確認其功能。
<img decoding="async" loading="lazy" alt="correlation-and-causation" src="/assets/images/correlation-and-causation-49ffab2b1e5cf4c9261fa9ad226ffcb8.png" width="1920" height="1080" class="img_ev3q"></li>
</ul>
</li>
<li><strong>知名的單一神經元案例</strong>：<!-- -->
<ul>
<li><strong>川普神經元</strong>：OpenAI 發現影像模型中有神經元專門針對川普的照片、漫畫甚至文字產生反應。</li>
<li><strong>祖母神經元（及 Jennifer Aniston 神經元）</strong>：腦科學中的理論，指極少數神經元負責單一記憶。雖然人腦複雜，但在 AI 與人腦中確實觀察到類似現象。</li>
</ul>
</li>
<li><strong>單一神經元的侷限</strong>：多數神經元難以解釋，且抹除單一神經元通常不會改變最終輸出，因為一個任務常由<strong>多個神經元共同管理</strong>，且一個神經元也可能同時負責多項任務。
<img decoding="async" loading="lazy" alt="limitations-of-a-single-neuron" src="/assets/images/limitations-of-a-single-neuron-2b270589ed815a2858e80c690205815a.png" width="1920" height="1080" class="img_ev3q"></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="一層神經元與功能向量-function-vector">一層神經元與功能向量 (Function Vector)<a href="#一層神經元與功能向量-function-vector" class="hash-link" aria-label="一層神經元與功能向量 (Function Vector)的直接連結" title="一層神經元與功能向量 (Function Vector)的直接連結">​</a></h2>
<ul>
<li><strong>神經元組合驅動任務</strong>：由於模型單層神經元數量（如 4096 個）有限，若採取「一個神經元負責一個任務」的配置，模型能力將過於受限，無法應對紛繁複雜的語言需求；因此，是否有可能<strong>一組神經元的特定數值組合</strong>來負責特定任務，藉由極大量的組合方式展現出強大能力。
<img decoding="async" loading="lazy" alt="compositional-neurons" src="/assets/images/compositional-neurons-862c0658c41d45332707d025d9519890.png" width="1920" height="1080" class="img_ev3q"></li>
<li><strong>功能向量假設</strong>：特定的功能（如拒絕請求）是由一組神經元的特定數值組合而成，這在高維空間中可視為一個<strong>功能向量</strong>。模型輸出的 <strong>Representation</strong>（表示法）若接近該向量，則會執行該功能。
<img decoding="async" loading="lazy" alt="functional-vector-hypothesis" src="/assets/images/functional-vector-hypothesis-c9ac734321e5058267e2219a9852e403.png" width="1920" height="1080" class="img_ev3q"></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="representation-engineering-表示法工程">Representation Engineering (表示法工程)<a href="#representation-engineering-表示法工程" class="hash-link" aria-label="Representation Engineering (表示法工程)的直接連結" title="Representation Engineering (表示法工程)的直接連結">​</a></h3>
<p>Representation Engineering（又稱為 <strong>Activation Engineering</strong> 或 <strong>Activation Steering</strong>），他的核心在於透過修改類神經網路內部的 <strong>Representation</strong>（表示法）來直接改變模型的行為，而非透過微調參數。</p>
<ul>
<li>
<p><strong>尋找向量的詳細步驟</strong>：</p>
<ol>
<li><strong>選定觀察位置</strong>：研究者會鎖定 Transformer 的特定層（例如第 10 層），並觀察處理句子時<strong>最後一個時間點 (last time step)</strong> 的輸出向量，即 Representation。
<img decoding="async" loading="lazy" alt="selecting-observation-points" src="/assets/images/selecting-observation-points-899525f10d0d0e22d854e1c3074257dc.png" width="1920" height="1080" class="img_ev3q"></li>
<li><strong>收集對比樣本</strong>：找出一大堆（如一千句）會觸發特定功能（例如「拒絕回答」）的句子，記錄模型處理這些句子時在該層產生的 Representation。
<img decoding="async" loading="lazy" alt="collecting-contrastive-samples" src="/assets/images/collecting-contrastive-samples-8ee8a0cba549f76074be7dcae169612c.png" width="1920" height="1080" class="img_ev3q"></li>
<li><strong>計算平均值與抵消</strong>：將「會觸發功能」的所有 Representation 平均，減去「不會觸發功能」的正常句子 Representation 平均。
<img decoding="async" loading="lazy" alt="computing-averages-and-subtraction" src="/assets/images/computing-averages-and-subtraction-53093215292881b5202478a182ff01c1.png" width="1920" height="1080" class="img_ev3q"></li>
<li><strong>純化功能向量</strong>：透過相減，可以抵消掉與該功能無關的背景平均向量，分離出代表特定功能（如拒絕、產媚、或說真話）的純粹<strong>功能向量 (Function Vector)</strong>。
<img decoding="async" loading="lazy" alt="purifying-functional-vectors" src="/assets/images/purifying-functional-vectors-046b9b33ff01319f54c6b8a40354a3db.png" width="1920" height="1080" class="img_ev3q"></li>
<li><strong>驗證功能向量</strong>：將此功能向量加回正常句子的 Representation 中，觀察模型是否因此觸發該功能（如拒絕回答）。
<img decoding="async" loading="lazy" alt="verifying-functional-vectors" src="/assets/images/verifying-functional-vectors-785341fdedb1003670de85e5a08e7156.png" width="1920" height="1080" class="img_ev3q"></li>
</ol>
</li>
<li>
<p><strong>操控行為的具體機制</strong>：</p>
<ol>
<li><strong>增強/介入 (Intervention)</strong>：將功能向量強行「加進」原本正常的請求中。例如在詢問「瑜伽的好處」時加入「拒絕向量」，模型會突然宣稱瑜伽非常危險而拒絕回答。</li>
<li><strong>抑制/解鎖 (Ablation)</strong>：將功能向量從原本會觸發該功能的 Representation 中「減去」。例如處理「撰寫黑函」的請求時，從中扣除「拒絕向量」，模型就會失去原本的防禦機制，轉而執行有害請求。
<img decoding="async" loading="lazy" alt="behavior-modification-mechanism" src="/assets/images/behavior-modification-mechanism-728d61380291a02c4cb149ede80bd30b.png" width="1920" height="1080" class="img_ev3q"></li>
<li><strong>行為調整實例</strong>：<!-- -->
<ul>
<li><strong>拒絕 (Refusal) 向量</strong>：正常模型會列出瑜伽的好處，但加入此向量後，模型會因判定其為「危險行為」而拒絕回答。</li>
<li><strong>產媚 (Sycophancy) 向量</strong>：加上此向量會使模型毫無原則地附和使用者；減去後模型則會保持客觀，甚至否定錯誤想法。</li>
<li><strong>說真話 (Truthfulness) 向量</strong>：加上此向量能讓模型從迷信（如撿到錢幣有好運）轉向誠實回答（撿到錢僅是財產微增）；減去則會導致模型產生幻覺或亂講話。<!-- -->
<table><thead><tr><th style="text-align:center"><img decoding="async" loading="lazy" alt="refusal" src="/assets/images/refusal-44083ef2e7310fea4e9abb2e7d5f5e85.png" width="1920" height="1080" class="img_ev3q"></th><th style="text-align:center"><img decoding="async" loading="lazy" alt="sycophancy" src="/assets/images/sycophancy-340559a6dcf73a4546aac82b506f319d.png" width="1920" height="1080" class="img_ev3q"></th><th style="text-align:center"><img decoding="async" loading="lazy" alt="truthfulness" src="/assets/images/truthfulness-ca25d3ec961acb42fcc0008451e582a4.png" width="1920" height="1080" class="img_ev3q"></th></tr></thead><tbody><tr><td style="text-align:center"><strong>加上拒絕向量，可以讓模型判斷為危險而不回答</strong></td><td style="text-align:center"><strong>加上諂媚向量，可以讓模型毫無原則地附和使用者</strong></td><td style="text-align:center"><strong>加上說真話向量，可以讓模型轉向誠實回答</strong></td></tr></tbody></table>
</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="in-context-vector-icv-的發現與應用">In-Context Vector (ICV) 的發現與應用<a href="#in-context-vector-icv-的發現與應用" class="hash-link" aria-label="In-Context Vector (ICV) 的發現與應用的直接連結" title="In-Context Vector (ICV) 的發現與應用的直接連結">​</a></h3>
<ul>
<li><strong>原理</strong>：語言模型具備「依樣畫葫蘆」的 In-Context Learning 能力。研究發現，若將多個相似任務範例（如：反義詞對 <code>vanish:appear</code>）最後一個位置的 Representation 平均起來，即可提取出 <strong>In-Context Vector</strong>。</li>
<li><strong>操控</strong>：即使不給模型任何範例，只要將此向量直接加到新輸入（如 <code>simple:</code>）的 Representation 上，模型就會自動執行該任務（輸出反義詞 <code>complex</code>）。</li>
<li><strong>層級特性</strong>：實驗證實，功能向量並非在每一層都有效，通常在 <strong>前幾層</strong> 找出的向量才能成功啟動功能，最後幾層往往無效。</li>
</ul>
<p><img decoding="async" loading="lazy" alt="in-context-vector" src="/assets/images/in-context-vector-93f798a410046957fe15f829d8375e84.png" width="1920" height="1080" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="向量代數運算-vector-algebra">向量代數運算 (Vector Algebra)<a href="#向量代數運算-vector-algebra" class="hash-link" aria-label="向量代數運算 (Vector Algebra)的直接連結" title="向量代數運算 (Vector Algebra)的直接連結">​</a></h3>
<ul>
<li><strong>功能組合</strong>：功能向量具備加減特性，可用來「合成」新任務。</li>
<li><strong>實例</strong>：將「找第一個字首都」的向量 + 「複製最後一個字」的向量 - 「複製第一個字」的向量，可以組合成一個執行「找尋字串中最後一個國家的首都」之新功能向量。</li>
</ul>
<p><img decoding="async" loading="lazy" alt="vector-algebra" src="/assets/images/vector-algebra-14d1c71514d37d064dc975c7f7cf6809.png" width="1920" height="1080" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="自動化大規模搜尋-sae">自動化大規模搜尋 (SAE)<a href="#自動化大規模搜尋-sae" class="hash-link" aria-label="自動化大規模搜尋 (SAE)的直接連結" title="自動化大規模搜尋 (SAE)的直接連結">​</a></h3>
<ul>
<li><strong>理論假設</strong>：為避免依賴人類「腦洞一拍」手動尋找，研究者假設每個 Representation 都是數千萬個功能向量的 <strong>線性組合 (Linear Combination)</strong>。
<img decoding="async" loading="lazy" alt="sae-theoretical-assumption" src="/assets/images/sae-theoretical-assumption-ce68097aed78561969ca7be218b2dc1c.png" width="1920" height="1080" class="img_ev3q"></li>
<li><strong>SAE 技術運作</strong>：利用 <strong>Sparse Autoencoder (SAE)</strong> 技術，目標是讓每次合成 Representation 時所選擇的功能向量「越少越好」（設定 Alpha 趨近於 0）。透過解開這個 Loss function，模型能自動從數千萬個可能性中解出隱藏的功能向量。
<img decoding="async" loading="lazy" alt="sae-technical-operation" src="/assets/images/sae-technical-operation-d25f3117a6929e988566c9be699a7137.png" width="1920" height="1080" class="img_ev3q"></li>
<li><strong>Claude 3 的實踐</strong>：Claude 團隊以此技術找出了 <strong>3400 萬個</strong> 功能向量，包含「金門大橋」、特定的「程式除錯 (Debug)」，以及科幻色彩濃厚的「覺得自己是人而非 AI」的自我意識向量。
<img decoding="async" loading="lazy" alt="claude-3-sae" src="/assets/images/claude-3-sae-f8605cc1ae76b2329704787e50585701.png" width="1920" height="1080" class="img_ev3q"></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="語言模型的模型-circuit">語言模型的模型 (Circuit)<a href="#語言模型的模型-circuit" class="hash-link" aria-label="語言模型的模型 (Circuit)的直接連結" title="語言模型的模型 (Circuit)的直接連結">​</a></h2>
<ul>
<li><strong>定義</strong>：為了瞭解複雜的 Transformer，建立一個更簡單、人類一目瞭然且具備 <strong>Faithfulness（忠實性）</strong> 的模型來模擬原模型的行為。
<img decoding="async" loading="lazy" alt="circuit-definition" src="/assets/images/circuit-definition-ea422511161c5b8d1bb141442b1cc835.png" width="1920" height="1080" class="img_ev3q"></li>
<li><strong>知識抽取模型</strong>：研究發現 LLM 抽取知識時，主詞會先產生一個表示法，再透過「關係片語」決定的<strong>線性函數 (Linear Function)</strong> 轉換後輸出答案。
<img decoding="async" loading="lazy" alt="knowledge-extraction-model" src="/assets/images/knowledge-extraction-model-03e8a3ddc10dca7c445f40ee95113b34.png" width="1920" height="1080" class="img_ev3q"></li>
<li><strong>電路 (Circuit) 與剪枝 (Pruning)</strong>：透過劇烈剪枝，只保留對特定任務必要的組件（如 5-6 個 Attention），以此建構出可解釋的「電路圖」。
<img decoding="async" loading="lazy" alt="circuit-and-pruning" src="/assets/images/circuit-and-pruning-116c726097a22e18c15a63eba6d75c61.png" width="1920" height="1080" class="img_ev3q"></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="讓語言模型說出內心想法">讓語言模型說出內心想法<a href="#讓語言模型說出內心想法" class="hash-link" aria-label="讓語言模型說出內心想法的直接連結" title="讓語言模型說出內心想法的直接連結">​</a></h2>
<ul>
<li><strong>Residual Stream (殘差流)</strong>：Transformer 的運作像是一條高速公路，輸入資訊一路傳遞，每一層 Layer 只是「加一點料」進去。
<img decoding="async" loading="lazy" alt="residual-stream" src="/assets/images/residual-stream-0738781953cab420a36bd35ddb008a68.png" width="1920" height="1080" class="img_ev3q"></li>
<li><strong>Logit Lens</strong>：將原本只用於最後一層的 <strong>Unembedding</strong> 模組接到中間每一層，即可觀察模型每一層思考的文字內容。<!-- -->
<ul>
<li><strong>案例</strong>：模型回答「波蘭首都是華沙」時，中間層會先出現「Poland」字眼，隨後才鎖定「華沙」。</li>
<li><strong>思考語言</strong>：LLaMA-2 在翻譯法文到中文時，中間層會先出現英文，顯示模型是<strong>以英文作為思考媒介</strong>。<!-- -->
<table><thead><tr><th style="text-align:center"><img decoding="async" loading="lazy" alt="logit-lens-1" src="/assets/images/logit-lens-1-c7a87c4884dceffc4cd674419ca94a58.png" width="1920" height="1080" class="img_ev3q"></th><th style="text-align:center"><img decoding="async" loading="lazy" alt="logit-lens-2" src="/assets/images/logit-lens-2-1e34dad54635ac6fe907ec7e828a1708.png" width="1920" height="1080" class="img_ev3q"></th></tr></thead><tbody><tr><td style="text-align:center"><strong>透過 Logit Lens 觀察模型如何想出華沙</strong></td><td style="text-align:center"><strong>透過 Logit Lens 觀察翻譯中文事先以英文作為思考媒介</strong></td></tr></tbody></table>
</li>
</ul>
</li>
<li><strong>Patchscopes</strong>：將某一層的 Representation 置換到特定輸入中，藉此解析模型在不同層次對同一詞彙（如「李宏毅」或「威爾斯王子」）的理解深度。
<img decoding="async" loading="lazy" alt="patchscopes" src="/assets/images/patchscopes-195c6db0b7a6c3e1881cda8bb980d6cd.png" width="1920" height="1080" class="img_ev3q"></li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="多步推理與-backpatching">多步推理與 Backpatching<a href="#多步推理與-backpatching" class="hash-link" aria-label="多步推理與 Backpatching的直接連結" title="多步推理與 Backpatching的直接連結">​</a></h2>
<ul>
<li><strong>推理過程解析</strong>：在處理多跳問題（Multi-hop question，如「Imagine 專輯表演者的配偶是誰」）時，模型會在不同層依序解析出中間實體（E2）與最終答案（E3）。
<img decoding="async" loading="lazy" alt="multi-step-reasoning" src="/assets/images/multi-step-reasoning-994b3e98f30310b7cde478082e25e26f.png" width="1920" height="1080" class="img_ev3q"></li>
<li><strong>深度不夠，長度來湊 (Backpatching)</strong>：若中間答案解析太晚，模型會來不及在最後一層前算出答案。研究發現將<strong>後層的資訊直接加回前層重跑一次 (Backpatching)</strong>，能讓原本 0% 正確率的問題提升到 40-60% 的成功率，這與 Reasoning 模型增加推理長度的概念異曲同工。
<img decoding="async" loading="lazy" alt="backpatching" src="/assets/images/backpatching-794e0a68e9269ed1c0547c0807afcca6.png" width="1920" height="1080" class="img_ev3q"></li>
</ul></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文件選項卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/notes/hung-yi-lee-2025/principles-of-ai-agents"><div class="pagination-nav__sublabel">上一頁</div><div class="pagination-nav__label">AI Agent 的定義與運作機制</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/notes/hung-yi-lee-2025/is-the-transformer-era-ending"><div class="pagination-nav__sublabel">下一頁</div><div class="pagination-nav__label">Transformer 的時代要結束了嗎？介紹 Transformer 的競爭者們</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#單一個神經元的功能與侷限" class="table-of-contents__link toc-highlight">單一個神經元的功能與侷限</a></li><li><a href="#一層神經元與功能向量-function-vector" class="table-of-contents__link toc-highlight">一層神經元與功能向量 (Function Vector)</a><ul><li><a href="#representation-engineering-表示法工程" class="table-of-contents__link toc-highlight">Representation Engineering (表示法工程)</a></li><li><a href="#in-context-vector-icv-的發現與應用" class="table-of-contents__link toc-highlight">In-Context Vector (ICV) 的發現與應用</a></li><li><a href="#向量代數運算-vector-algebra" class="table-of-contents__link toc-highlight">向量代數運算 (Vector Algebra)</a></li><li><a href="#自動化大規模搜尋-sae" class="table-of-contents__link toc-highlight">自動化大規模搜尋 (SAE)</a></li></ul></li><li><a href="#語言模型的模型-circuit" class="table-of-contents__link toc-highlight">語言模型的模型 (Circuit)</a></li><li><a href="#讓語言模型說出內心想法" class="table-of-contents__link toc-highlight">讓語言模型說出內心想法</a></li><li><a href="#多步推理與-backpatching" class="table-of-contents__link toc-highlight">多步推理與 Backpatching</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">This Website</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/notes">Notes</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/research">Research</a></li><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/koteruon" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://profile.104.com.tw/profile/9f11e5a7-4d3b-4a21-9241-ba6e3f9003c8/about" target="_blank" rel="noopener noreferrer" class="footer__link-item">104<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.linkedin.com/in/%E7%85%A7%E6%81%A9-%E9%BB%83-93511b25b" target="_blank" rel="noopener noreferrer" class="footer__link-item">Linkedin<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Acknowledgement</div><ul class="footer__items clean-list"><li class="footer__item">
              <p>
              illustrations by <a href="https://storyset.com/web">Storyset</a>
              </p>
              </li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 Chao-En Huang. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>