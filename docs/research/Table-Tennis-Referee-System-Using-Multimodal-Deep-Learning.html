<!doctype html>
<html lang="zh-Hant" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-research/Table-Tennis-Referee-System-Using-Multimodal-Deep-Learning" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Table Tennis Referee System Using Multimodal Deep Learning | Chao-En Huang</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://koteruon.github.io/images/icon/chao_en_huang_icon.png"><meta data-rh="true" name="twitter:image" content="https://koteruon.github.io/images/icon/chao_en_huang_icon.png"><meta data-rh="true" property="og:url" content="https://koteruon.github.io/docs/research/Table-Tennis-Referee-System-Using-Multimodal-Deep-Learning"><meta data-rh="true" property="og:locale" content="zh_Hant"><meta data-rh="true" name="docusaurus_locale" content="zh-Hant"><meta data-rh="true" name="docsearch:language" content="zh-Hant"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Table Tennis Referee System Using Multimodal Deep Learning | Chao-En Huang"><meta data-rh="true" name="description" content="&lt;HuggingFaceCard"><meta data-rh="true" property="og:description" content="&lt;HuggingFaceCard"><link data-rh="true" rel="icon" href="/images/icon/favicon.ico"><link data-rh="true" rel="canonical" href="https://koteruon.github.io/docs/research/Table-Tennis-Referee-System-Using-Multimodal-Deep-Learning"><link data-rh="true" rel="alternate" href="https://koteruon.github.io/docs/research/Table-Tennis-Referee-System-Using-Multimodal-Deep-Learning" hreflang="zh-Hant"><link data-rh="true" rel="alternate" href="https://koteruon.github.io/docs/research/Table-Tennis-Referee-System-Using-Multimodal-Deep-Learning" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Chao-En Huang RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Chao-En Huang Atom Feed">

<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-5X8N2TCV",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer")</script>




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.4d27f2bd.css">
<script src="/assets/js/runtime~main.838eb7c6.js" defer="defer"></script>
<script src="/assets/js/main.2364bb7a.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5X8N2TCV" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>


<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="跳至主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳至主要内容</a></div><nav aria-label="主導航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切換導覽列" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/images/icon/apple-touch-icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/images/icon/apple-touch-icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Chao-En</b></a><a class="navbar__item navbar__link" href="/about-me">About Me</a><a class="navbar__item navbar__link" href="/docs/notes">Notes</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/research">Research</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/koteruon" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="切換淺色/深色模式（當前為淺色模式）" aria-label="切換淺色/深色模式（當前為淺色模式）" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="回到頂部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="文件側邊欄" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/research">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/research/Master-Thesis">A Novel Table Tennis Stroke Recognition Method Using The Bimodal Deep Neural Networks with Skeletal-Temporal Transformer and Racket Geometric Features</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/docs/research/Table-Tennis-Referee-System-Using-Multimodal-Deep-Learning">Table Tennis Referee System Using Multimodal Deep Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/research/Table-Tennis-Trajectory-Landing-Point-and-Speed-Analysis-System">Table Tennis Trajectory Landing Point and Speed Analysis System</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/research/AI-Powered-Table-Tennis-Scoring-System-with-Ball-Launcher">AI Powered Table Tennis Scoring System with Ball Launcher</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/research/Enhancing-UNet3Plus-Robustness-with-Weight-Perturbation">Enhancing UNet3+ Robustness with Weight Perturbation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/research/Exploiting-Minimal-Distance-for-Automatic-Weighted-Color-Transfer">Exploiting Minimal Distance for Automatic Weighted Color Transfer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/research/Image-Encryption-and-Data-Embedding-Using-Transformation-Techniques">Image Encryption and Data Embedding Using Transformation Techniques</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="頁面路徑"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="主頁面" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Table Tennis Referee System Using Multimodal Deep Learning</span><meta itemprop="position" content="1"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本頁導覽</button></div><div class="theme-doc-markdown markdown"><header><h1>Table Tennis Referee System Using Multimodal Deep Learning</h1></header>
<!-- -->
<div style="border:1px solid #D0D7DE;border-radius:6px;background-color:#FFFFFF;padding:16px;font-size:14px;line-height:1.5;color:#24292E;margin:15px 0;font-family:-apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;"><div style="display:flex;align-items:center;margin-bottom:8px"><img src="/images/icon/hf-logo-pirate.svg" alt="Hugging Face Logo" style="width:20px;height:20px;margin-right:8px"><a href="https://huggingface.co/koteruon/yolov7x_3classes" target="_blank" rel="noopener noreferrer" style="font-weight:600;color:#0969DA;text-decoration:none">yolov7x_3classes</a></div><div style="font-size:12px;margin:8px 0;color:#57606A"></div><div style="font-size:12px;color:#57606A;display:flex;align-items:center"><span style="width:12px;height:12px;border-radius:100%;background-color:#DA5B0B;display:inline-block;margin-right:6px"></span>Pytorch Model</div></div>
<div style="border:1px solid #D0D7DE;border-radius:6px;background-color:#FFFFFF;padding:16px;font-size:14px;line-height:1.5;color:#24292E;margin:15px 0;font-family:-apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;"><div style="display:flex;align-items:center;margin-bottom:8px"><img src="/images/icon/hf-logo-pirate.svg" alt="Hugging Face Logo" style="width:20px;height:20px;margin-right:8px"><a href="https://huggingface.co/koteruon/hitnet_serve_and_stroke" target="_blank" rel="noopener noreferrer" style="font-weight:600;color:#0969DA;text-decoration:none">hitnet_serve_and_stroke</a></div><div style="font-size:12px;margin:8px 0;color:#57606A"></div><div style="font-size:12px;color:#57606A;display:flex;align-items:center"><span style="width:12px;height:12px;border-radius:100%;background-color:#DA5B0B;display:inline-block;margin-right:6px"></span>Pytorch Model</div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="experimental-results">Experimental Results<a href="#experimental-results" class="hash-link" aria-label="Experimental Results的直接連結" title="Experimental Results的直接連結">​</a></h2>
<div><link rel="preload" href="https://i.ytimg.com/vi/vh6rItcCGlk/hqdefault.jpg" as="image"><article class="yt-lite" data-title="基於多模態深度學習之桌球自動裁判系統_112年全國運動會" style="background-image:url(https://i.ytimg.com/vi/vh6rItcCGlk/hqdefault.jpg);--aspect-ratio:56.25%"><button type="button" class="lty-playbtn" aria-label="Watch 基於多模態深度學習之桌球自動裁判系統_112年全國運動會"></button></article></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="explanatory-videos">Explanatory Videos<a href="#explanatory-videos" class="hash-link" aria-label="Explanatory Videos的直接連結" title="Explanatory Videos的直接連結">​</a></h2>
<div><link rel="preload" href="https://i.ytimg.com/vi/9BYXCaCJvdQ/hqdefault.jpg" as="image"><article class="yt-lite" data-title="基於多模態深度學習之桌球自動裁判系統" style="background-image:url(https://i.ytimg.com/vi/9BYXCaCJvdQ/hqdefault.jpg);--aspect-ratio:56.25%"><button type="button" class="lty-playbtn" aria-label="Watch 基於多模態深度學習之桌球自動裁判系統"></button></article></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="abstract">Abstract<a href="#abstract" class="hash-link" aria-label="Abstract的直接連結" title="Abstract的直接連結">​</a></h2>
<p>This study pioneers the use of bimodal action recognition for table tennis video analysis, integrating RGB images and pose data to detect rally events.
A YOLOv7-based framework with pose estimation distinguishes ball, player, and table positions, enhancing system speed and accuracy.
By combining ball trajectories with player actions, the system identifies rally start and end times, embedding results into output videos for easy analysis.</p>
<p><img decoding="async" loading="lazy" alt="Table-Tennis-Video-Timeline-Diagram" src="/assets/images/Table-Tennis-Video-Timeline-Diagram-a75d4fdaf2fff49cb7621228c3480913.png" width="3564" height="920" class="img_ev3q"></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="method-flowchart">Method Flowchart<a href="#method-flowchart" class="hash-link" aria-label="Method Flowchart的直接連結" title="Method Flowchart的直接連結">​</a></h2>
<p>The workflow of this study is as follows:</p>
<ol>
<li>First, object detection is performed on the input video to identify the ball, players, and table, along with human pose estimation.
An object detection model is used to predict the bounding boxes for each object, while pose estimation is applied to the players to detect key body joint coordinates.</li>
<li>Next, a bimodal deep learning network is built using these two types of data to perform action recognition for each player.
The ball trajectory coordinates and the action recognition results are then used to determine the conclusion of a table tennis point.</li>
<li>Finally, the results are integrated and displayed in the output video.</li>
</ol>
<p><img decoding="async" loading="lazy" alt="Method-Flowchart" src="/assets/images/Method-Flowchart-c67e2d12d1c7887ae2ce8bac9f6ec5df.png" width="3874" height="2223" class="img_ev3q"></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="bimodal-based-action-recognition-model">Bimodal-based Action Recognition Model<a href="#bimodal-based-action-recognition-model" class="hash-link" aria-label="Bimodal-based Action Recognition Model的直接連結" title="Bimodal-based Action Recognition Model的直接連結">​</a></h2>
<p>This study aims to detect the start of each point in a table tennis match by identifying the <strong>serve actions</strong>, thereby enabling accurate recognition of players&#x27; continuous movements within each frame.</p>
<p>Recent works have leveraged <strong>spatiotemporal convolutional networks</strong> to capture both <strong>spatial</strong> and <strong>temporal motion features</strong> in video frames, enhancing action recognition performance.
However, these methods often overlook the <strong>interactions between players and surrounding objects</strong>, such as the <strong>ball&#x27;s movement across the table</strong>, which is vital to the hitting process.</p>
<p>To address this gap, we propose a <strong>dual-modal approach</strong> that incorporates both <strong>player-environment interactions</strong> and <strong>human pose estimation</strong>.
The model utilizes the <strong>SlowFast network</strong> for feature extraction, processing both <strong>slow</strong> and <strong>fast temporal scales</strong> to capture long- and short-term motion information.
<strong>Region of Interest (RoI) alignment</strong> is employed to focus on key objects and players by applying the detected bounding boxes.
Additionally, we introduce <strong>interaction modules</strong>—<strong>person-to-person</strong>, <strong>person-to-object</strong>, and <strong>hands-to-object interactions</strong>—capturing complex relationships between the target objects.
These interactions are computed using a <strong>cross-attention mechanism</strong>, followed by <strong>intra-modality aggregation</strong> to refine the extracted features.
Finally, <strong>temporal interaction</strong> and <strong>feature fusion modules</strong> are applied to integrate information across both time and modalities, resulting in improved action classification accuracy.</p>
<p><img decoding="async" loading="lazy" alt="Network-Architecture" src="/assets/images/Network-Architecture-e27e25f5a9baaf6e855a322e1067b82b.png" width="3163" height="1980" class="img_ev3q"></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="experimental-results-1">Experimental Results<a href="#experimental-results-1" class="hash-link" aria-label="Experimental Results的直接連結" title="Experimental Results的直接連結">​</a></h2>
<p><img decoding="async" loading="lazy" alt="serve" src="/assets/images/serve-5ae289f1c6c9b79cb8b56df8a19424a4.png" width="1600" height="1200" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="stroke" src="/assets/images/stroke-d5dce20845a9cbb756dabf6d64028ec4.png" width="3600" height="1300" class="img_ev3q"></p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文件選項卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/research/Master-Thesis"><div class="pagination-nav__sublabel">上一頁</div><div class="pagination-nav__label">A Novel Table Tennis Stroke Recognition Method Using The Bimodal Deep Neural Networks with Skeletal-Temporal Transformer and Racket Geometric Features</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/research/Table-Tennis-Trajectory-Landing-Point-and-Speed-Analysis-System"><div class="pagination-nav__sublabel">下一頁</div><div class="pagination-nav__label">Table Tennis Trajectory Landing Point and Speed Analysis System</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#experimental-results" class="table-of-contents__link toc-highlight">Experimental Results</a></li><li><a href="#explanatory-videos" class="table-of-contents__link toc-highlight">Explanatory Videos</a></li><li><a href="#abstract" class="table-of-contents__link toc-highlight">Abstract</a></li><li><a href="#method-flowchart" class="table-of-contents__link toc-highlight">Method Flowchart</a></li><li><a href="#bimodal-based-action-recognition-model" class="table-of-contents__link toc-highlight">Bimodal-based Action Recognition Model</a></li><li><a href="#experimental-results-1" class="table-of-contents__link toc-highlight">Experimental Results</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">This Website</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/notes">Notes</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/research">Research</a></li><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/koteruon" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://pda.104.com.tw/profile/preview?vno=75wef33ky" target="_blank" rel="noopener noreferrer" class="footer__link-item">104<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.linkedin.com/in/%E7%85%A7%E6%81%A9-%E9%BB%83-93511b25b" target="_blank" rel="noopener noreferrer" class="footer__link-item">Linkedin<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Acknowledgement</div><ul class="footer__items clean-list"><li class="footer__item">
              <p>
              illustrations by <a href="https://storyset.com/web">Storyset</a>
              </p>
              </li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Chao-En Huang. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>